---
type: linkedin-post
status: published
created: 2025-12-27
published_date: '2025-12-27T10:17:16Z'
post_url: https://www.linkedin.com/feed/update/urn:li:share:7410624648410984448/
topic: ai-coding-skill-gap
theme: practical-engineering
persona: tech-leader
audiences: [senior-engineers, engineering-managers, tech-leads]
reference: Andrej Karpathy X thread (Dec 27, 2025)
reference_url: https://x.com/karpathy/status/1874921860441329940
performance_metrics:
  impressions: 1188
  member_reached: 0
  profile_views: 0
  followers: 0
  reactions: 24
  comments: 9
  reposts: 4
  saves: 0
  sends_on_linkedin: 0
---

# Response to Karpathy's "Skill Issue" Thread


## X Comment (for Karpathy's thread)

The skill gap isn't about mastering agents, MCP, or the tool alphabet soup. It's a mental shift. I think AI adoption is a workflow decision, not a tool decision. You need to change how you work with AI.


## LinkedIn Post (with Karpathy screenshot)

[SCREENSHOT: Karpathy's X thread]

"I've never felt this much behind as a programmer."
That's Andrej Karpathy. Built Tesla's AI. Former OpenAI.
If he feels behind, what does that mean for us?

This isn't impostor syndrome. The ground is actually shifting.

But here's what caught my attention:

"Failure to claim the boost feels decidedly like skill issue."

He's right. There IS a skill issue. And it has a pattern.

The gap isn't tools. It's mental model.

Most engineers are stuck at one level:

→ "AI follows my instructions"
→ Step-by-step scaffolding
→ Guardrails everywhere
→ Micromanaging the model

The unlock is a different level:

→ "AI solves my problem"
→ Give WHAT and WHY
→ Let AI figure out HOW
→ Validate outcomes, not steps

Same tools. Different approach. Dramatically different results.

Vercel discovered this. They deleted 80% of their agent's tools. Success rate went from 80% to 100%. Speed: 3.5x faster.

The insight: "We were constraining reasoning because we didn't trust the model to reason."

The real skill gap:

It's not mastering agents, MCP, hooks, or the tool alphabet soup Karpathy lists.

It's trusting the model to think.

That's the hardest shift. We're trained to give instructions. These models need context.

Here's the thing Karpathy's list reveals:

He names 15+ concepts: agents, subagents, prompts, contexts, memory, modes, permissions, tools, plugins, skills, hooks, MCP, LSP, slash commands, workflows, IDE integrations...

Most people see that list and think: "I need to master all of these."

Wrong frame.

AI adoption is a workflow decision, not a tool decision.

The tools will keep changing. New ones every month. The list will only grow.

What won't change:
- Knowing WHAT you're trying to achieve
- Understanding WHY it matters
- Designing workflows that validate output
- Building skills that compound regardless of tools

The earthquake Karpathy describes is real. But the "manual" for the alien tool is emerging:

1. WHAT and WHY over HOW (context over instructions)
2. WHO (system identity, principles, constraints)
3. Outcomes over process

The engineers who make this shift will claim the 10X.

The ones who chase every new tool will feel increasingly behind.

Karpathy is right: roll up your sleeves.

But roll them up for workflow and skills. The tools will follow.

What level are you operating at? Instructions or context?

#AICoding #SoftwareEngineering #EngineeringLeadership


## First Comment (post immediately after)

The progression I've been mapping:

**Level 3:** "AI follows my instructions"
→ You specify HOW. Step-by-step. Guardrails everywhere.

**Level 4:** "AI solves my problem"
→ You specify WHAT and WHY. AI figures out HOW.

**Level 5:** "AI reasons about the system"
→ You give context, constraints, and identity. AI makes decisions. You validate outcomes.

Level 3 to 4 is the hardest jump.

It means trusting the model to think. Writing success criteria instead of execution steps. Giving up control of HOW.

Most teams have the tooling for Level 4. They don't have the mindset.

I wrote more about this progression recently: [LINK TO LEVELS POST]


## Second Comment (links to AI Adoption post)

"AI adoption is a workflow decision, not a tool decision."

I wrote about this last month after implementing AI-assisted development across multiple teams.

The pattern was clear:
- 20% of engineers became 5x more productive
- 60% saw 2x gains
- 20% saw minimal benefit

Same tools. Same training. Same access.

The difference? The 5x group focused on workflow and validation, not tool mastery.

Full breakdown: [LINK TO AI ADOPTION POST]


## Third Comment (5 skills + CTA)

What's interesting: Karpathy lists the complexity (agents, subagents, prompts, contexts, memory, MCP, hooks...).

But the answer isn't mastering each piece individually.

It's building 5 skills that work regardless of which tools you use:

1. Problem Framing - turn vague into specific
2. Decomposition - split into verifiable steps
3. Evaluation - know "done" before you start
4. Correction - fix the 20%, don't regenerate
5. Systems Thinking - make it easier next time

Tools change. These skills compound.

This is what I am exploring and experimenting at INNOMIZE. If you have the same ideas, let's discuss and share insights.


## Alternative Hook Options

**Hook A (current):** "Andrej Karpathy just posted this..."

**Hook B:** "The person who built Tesla's AI feels 'behind as a programmer.' Read that again."

**Hook C:** "If Karpathy feels behind, what does that mean for the rest of us?"

**Hook D:** "Andrej Karpathy calls it a 'skill issue.' He's right. And the skill has a name."


## Connection to Previous Posts (The Trilogy)

This post ties together your previous work:

| Comment | Links To | Published |
|---------|----------|-----------|
| First | 6 Levels of AI Coding | Dec 25, 2025 |
| Second | AI Adoption Is Wrong | Nov 18, 2025 |
| Third | Workshop 5 Skills (teaser) | Upcoming |

**Why this works:**
- Main post stands alone (new audience gets full insight)
- Comments create depth for engaged readers
- Both previous posts PRECEDE Karpathy's observation (credibility)
- Third comment seeds the workshop content without being promotional

**The narrative arc:**
1. AI Adoption Is Wrong → Workflow > tools
2. 6 Levels → Mental model progression
3. Karpathy Response → Authority validates both + ties them together

Karpathy's post becomes the "proof point" that your framework was right.


## Substack Alternative

If posting on Substack instead of LinkedIn:

**Title options:**
- "Karpathy Feels Behind. Here's What That Means."
- "The Skill Issue Has a Name"
- "Why Even AI Builders Feel Behind"

**Format:**
- Include full Karpathy quote (not just screenshot)
- Expand on the levels framework with more detail
- Add the Vercel case study with specifics
- Close with the 5 skills preview
- CTA: Subscribe for the full breakdown

This could work as a Note (short) or Article (long-form) depending on depth.
