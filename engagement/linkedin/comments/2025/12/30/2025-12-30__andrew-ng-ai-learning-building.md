---
type: linkedin-engagement
created: '2025-12-30T03:56:00Z'
last_updated: '2025-12-30T03:56:00Z'

author:
  name: "Andrew Ng"
  profile: "people/andrew-ng.md"

post:
  source: "external"
  url: "https://www.linkedin.com/posts/andrewyng_top-stories-of-2025-big-ai-poaches-talent-activity-7411468553121460224-_b6Z"
  date: '2025-12-30'
  reactions: 1858
  comments_count: 0
  reposts: 0
  theme: "AI skill development methodology"
  angle: "Structured learning + building beats just diving in"
  key_points:
    - "Plunging into building without courses leads to reinventing the wheel badly"
    - "Interview failures: custom RAG chunking, duplicate evaluation techniques, messy context management"
    - "Courses + hands-on building together is the winning formula"
    - "Agentic coders make building easier than ever"
  hashtags: []

thread_topic: "AI learning methodology - courses + building"
topic_tags: [ai-development, learning, engineering-skills, practical-engineering]

engagement_status: "posted"
response_received: false
follow_up_needed: false
follow_up_date: null
---

## Original Post

Another year of rapid AI advances has created more opportunities than ever for anyone — including those just entering the field — to build software. In fact, many companies just can't find enough skilled AI talent. Every winter holiday, I spend some time learning and building, and I hope you will too. This helps me sharpen old skills and learn new ones, and it can help you grow your career in tech. To be skilled at building AI systems, I recommend that you: - Take AI courses - Practice building AI systems - (Optionally) read research papers Let me share why each of these is important. I've heard some developers advise others to just plunge into building things without worrying about learning. This is bad advice! Unless you're already surrounded by a community of experienced AI developers, plunging into building without understanding the foundations of AI means you'll risk reinventing the wheel or — more likely — reinventing the wheel badly! For example, during interviews with job candidates, I have spoken with developers who reinvented standard RAG document chunking strategies, duplicated existing evaluation techniques for Agentic AI, or ended up with messy LLM context management code. If they had taken a couple of relevant courses, they would have better understood the building blocks that already exist. They could still rebuild these blocks from scratch if they wished, or perhaps even invent something superior to existing solutions, but they would have avoided weeks of unnecessary work. So structured learning is important! Moreover, I find taking courses really fun. Rather than watching Netflix, I prefer watching a course by a knowledgeable AI instructor any day! At the same time, taking courses alone isn't enough. There are many lessons that you'll gain only from hands-on practice. Learning the theory behind how an airplane works is very important to becoming a pilot, but no one has ever learned to be a pilot just by taking courses. At some point, jumping into the pilot's seat is critical! The good news is that by learning to use highly agentic coders, the process of building is the easiest it has ever been. And learning about AI building blocks might inspire you with new ideas for things to build. If I'm not feeling inspired about what projects to work on, I will usually either take courses or read research papers, and after doing this for a while, I always end up with many new ideas. Moreover, I find building really fun, and I hope you will too!

## Notable Comments

```yaml
- id: 1735530993000
  author: "Joseph Nogle, MBA, PMP"
  profile: null
  sentiment: "positive"
  content: |
The shift from "Zero-shot" to "Agentic Workflows" is the most significant pivot in AI for 2025. The bottleneck is no longer just the model intelligence, it is the design of the iterative loop. We are moving away from the era of the "perfect prompt" and into the era of the "perfect system". From a data perspective, this is a transition from linear processing to feedback loops. But from an EQ perspective, this requires a new level of trust in the technology. We are giving AI the autonomy to self-correct, reflect, and iterate before it presents a final output. The companies that win won't just have the best LLMs. They will have the best architectures for reflection and multi-agent collaboration. It is less about talking to the machine and more about managing the machine's own internal workflow. You are right to emphasize that "how we use" the models is finally becoming as important as the models themselves.
  reactions: 8
  insight: "System thinking over prompt engineering - aligns with our architecture angle"
  replies: []

- id: 1735530994000
  author: "Kris Kromer"
  profile: null
  sentiment: "positive"
  content: |
Strong perspective. One pattern I see once people do become skilled is that the bottleneck shifts very quickly. We're getting better at teaching individuals how to build AI systems. Where many organizations still struggle is deciding who owns outcomes once those systems move from learning environments into real workflows. In production, it's rarely a lack of technical skill that causes friction. It's unclear accountability. AI influences a decision, a human approves it, policy exists somewhere, and responsibility quietly diffuses. Skill development is necessary. But sustainable impact comes when organizations pair those skills with clear ownership and decision boundaries as systems scale.
  reactions: 5
  insight: "Accountability/ownership angle - connects to our embedded CTO positioning"
  replies: []

- id: 1735530995000
  author: "Guy Pistone"
  profile: null
  sentiment: "positive"
  content: |
I see many teams treating AI like a 'Plug-and-Play' utility, only to realize their unit economics are broken because they didn't understand the underlying token management or evaluation loops. High-leverage building requires a move from Stochastic building (trial and error) to Deterministic engineering. Structured courses provide the 'Source Code' for the developer's own logic. In 2026, the competitive moat won't have an agent; it will have an agentic system built on solid foundations that actually scales without burning a hole through the OpEx.
  reactions: 3
  insight: "Deterministic engineering vs stochastic building - good framing"
  replies: []
```

## Our Engagement

```yaml
- id: 1735531000000
  type: "comment"
  status: "draft"
  sentiment: "positive"
  content: |
This maps to something we've been seeing across AI development: the shift from prompt optimization to workflow design.

The developers who reinvent RAG chunking badly aren't missing prompting skills. They're missing workflow. They jump straight to tools without understanding the building blocks.

Courses teach the skills layer. Building teaches how skills connect. The workflow emerges from doing both.

Joseph Nogle's point is key: we're moving from "perfect prompt" to "perfect system." Same principle applies beyond coding. Content creation, research, analysis. The people getting results aren't better prompters. They have better workflows.
  strategy: "Connect to workflow → skills → tools framework, amplify Joseph Nogle's comment, extend beyond coding"
  replies: []
```

## Notes

- Andrew Ng: Highly influential AI educator, founder of DeepLearning.AI, former Google Brain
- Post aligns with our practical-engineering theme
- Strong connection to engineering-leadership angle (team learning, code review patterns)
- High engagement post (1858 reactions) - good visibility opportunity
- Question at end invites response from author
