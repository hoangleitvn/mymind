---
type: linkedin-engagement
created: '2026-01-14T08:35:00Z'
last_updated: '2026-01-15T14:20:00Z'

author:
  name: "Mart√≠ Norberto"
  linkedin_url: "https://es.linkedin.com/in/martinorberto"
  profile: "people/marti-norberto.md"

post:
  source: "external"
  url: "https://www.linkedin.com/posts/martinorberto_i-spent-months-obsessing-over-1-perfect-activity-7416783315795374080-Mudw"
  activity_id: "7416783315795374080"
  date: '2026-01-14'
  reactions: 11
  comments_count: 0
  reposts: 0
  theme: "AI reliability comes from system architecture, not prompts"
  angle: "AI maturity as density - prompts (air) ‚Üí workflows (liquid) ‚Üí agents (solid) ‚Üí multi-agent (steel)"
  key_points:
    - Spent months on perfect prompt, realized building castles on sand
    - Reliability doesn't come from model, comes from system around it
    - AI maturity evolves from volatile to solid
    - The magic is in the orchestration, not the LLM
    - Reliability is an engineering problem, not a prompting problem
  hashtags: []

thread_topic: "AI reliability through system architecture"
topic_tags: [ai-engineering, prompting, workflows, agents, reliability]

engagement_status: "conversation"
response_received: true
follow_up_needed: false
follow_up_date: null
---

## Original Post

I spent months obsessing over 1 "perfect" prompt. And realized I was building castles on sand. I thought the secret to AI was whispering the right words to the model. Until I tried to put it into production. ‚õîÔ∏è I saw hallucinations & Inconsistent outputs. I realized that reliability doesn't come from the model itself. It comes from the system you build around it. Think of AI maturity as "density." It evolves from volatile air to solid steel: üí® Prompts (The Air) ‚Üí Lightweight and scattered. ‚Üí Great for brainstorming, terrible for consistency. You ask, and you hope. üíß Workflows (The Liquid) ‚Üí Chains of logic. Step-by-step structures. ‚Üí We start controlling the flow, directing the output exactly where it needs to go. üß± Agents (The Solid) ‚Üí Now we have autonomy. ‚Üí The AI has tools. It can search, code, and execute actions. It stops being a chat and starts being a worker. ‚õìÔ∏è Multi-agent Systems (The Steel) ‚Üí The maximum density. ‚Üí Specialized agents checking each other's work. A team of experts, not a lone genius. This isn't just tech; it's architecture. I learned that the magic isn't in the LLM. It's in the orchestration. Shift your mindset: stop asking "which model is smarter?" and embrace "how robust is my structure?" Reliability is an engineering problem, not a prompting problem Are you still prompting, or are you building systems?

## Notable Comments

```yaml
- id: 1736844000000
  author: "Nil Monfort"
  profile: null
  sentiment: "positive"
  content: |
So true. Everyone's chasing the "perfect prompt" when the real game is building the structure around it...
  reactions: 1
  insight: "Echoes the main thesis"
  replies: []

- id: 1736844100000
  author: "Jeffrey Ticman"
  profile: null
  sentiment: "positive"
  content: |
Building reliable systems is key for AI success, not just prompts.
  reactions: 1
  insight: "Agreement with core message"
  replies: []

- id: 1736844200000
  author: "Esther Fanyan√†s i Ropero"
  profile: null
  sentiment: "positive"
  content: |
Agree. Seen this firsthand! Reliability comes from the system and everything depends on it.
  reactions: 1
  insight: "Personal experience validation"
  replies: []
```

## Our Engagement

```yaml
- id: 1736845000000
  type: "comment"
  status: "posted"
  sentiment: "positive"
  content: |
This is the shift I keep advocating: workflow first, skills second, tools last. The tool is 20% of the outcome. The workflow is 80%.

There is no perfect prompt. Better prompts without workflow just produce faster wrong answers.

What works: build the foundation before AI writes a line. Know what "correct" looks like. When mistakes happen, turn them into rules.

Reliability is engineering, not prompting.
  strategy: "Add Context - Share our 'workflow first, tools last' framework and real experience with CLAUDE.md rules"
  grounded_in:
    - content/innomize/ai-adoption-workflow-first.md
    - content/linkedin/2026/01/2026-01-14__ai-coding-lessons.md
    - content/linkedin/2026/01/2026-01-12__ai-hallucination-patterns.md
  replies:
    - id: 1736952000000
      author: "Mart√≠ Norberto"
      sentiment: "positive"
      content: |
This is the key shift. Teams stuck optimizing prompts are still in experimentation mode. Teams building workflows, rules, and feedback loops are the ones shipping reliable systems.
      reactions: 0
    - id: 1736952100000
      type: "our_reply"
      status: "draft"
      sentiment: "positive"
      content: |
Exactly. The feedback loop is what most teams skip. Every failure should become a rule. That's how the system learns, not the prompt.
```

## Notes

- Strong alignment with our "workflow first, tools last" framework
- His "density" metaphor (air ‚Üí liquid ‚Üí solid ‚Üí steel) is creative
- First engagement with this person
- His ending line matches our philosophy: "Reliability is an engineering problem, not a prompting problem"
- Good opportunity to share our framework and CLAUDE.md approach
