---
type: linkedin-engagement
created: '2026-01-14T08:40:00Z'
last_updated: '2026-01-14T08:40:00Z'

author:
  name: "Andrew Clark"
  linkedin_url: "https://www.linkedin.com/in/andrewclark-solutions"
  profile: "people/andrew-clark.md"

post:
  source: "external"
  url: "https://www.linkedin.com/posts/andrewclark-solutions_most-companies-dont-have-an-ai-problem-activity-7416843869671198720-bsNk"
  activity_id: "7416843869671198720"
  date: '2026-01-14'
  reactions: 43
  comments_count: 0
  reposts: 0
  theme: "Companies don't have AI problem, they have operating model issue"
  angle: "Clarity and intent before technology - governance, process, ownership, adoption"
  key_points:
    - Teams confused about priorities, data messy, no one owns outcomes
    - Winning orgs do less with intent, not more without direction
    - Get clear on problem, owner, success metrics, what must change
    - Only then bring in the technology
    - Speed without direction feels like motion. Clarity creates momentum.
    - Capabilities succeed when operated intentionally
  hashtags: []

thread_topic: "Operating model clarity before AI adoption"
topic_tags: [ai-adoption, operating-model, governance, ownership, clarity]

engagement_status: "posted"
response_received: false
follow_up_needed: false
follow_up_date: null
---

## Original Post

Most companies don't have an AI problem. They have operating model issue. They're moving fast… But not always in a direction. They're building pilots, demos, proofs of concept — and calling that progress. Meanwhile: • Teams are confused about priorities • Data is messy or misunderstood • No one clearly owns adoption or outcomes • And leaders are left wondering why "all this AI" isn't changing much The organizations that are actually winning with AI aren't doing more. They're doing less — with intent. They get brutally clear on: - What problem they're solving - Who owns it - How success will be measured - And what has to change for value to show up Only then do they bring in the technology. Speed without direction feels like motion. Clarity creates momentum towards real results. Don't leave your operating model as an afterthought. New capabilities fail not because the technology didn't work — but because no one defined how they would actually run. From day one, be clear on: • Governance — who decides, who approves, who owns risk • Processes — how work flows, not how slides look • Ownership — real accountability, not shared ambiguity • Adoption — how people will actually use it to create value Capabilities don't succeed by existing. - They succeed when they're operated intentionally. Strategy sets direction. - Operating models create results.

## Notable Comments

```yaml
- id: 1736845500000
  author: "Ahmed H. El Sheikh"
  profile: null
  sentiment: "positive"
  content: |
Spot on regarding the operating model. However, I'd say that experimentation should be part of that operating model. Sometimes we need pilots to discover the direction. But I agree with your core premise. Any pilot, no matter how small, needs defined metrics and ownership, otherwise it's just a cash burning exercise.
  reactions: 1
  insight: "Nuanced addition - experimentation needs metrics and ownership too"
  replies: []

- id: 1736845600000
  author: "Subrata Chatterji"
  profile: null
  sentiment: "positive"
  content: |
Yes, most AI efforts don't stall because the model underperformed. They stall when decisions get blurry after the pilot. Who can override the output? What happens when speed conflicts with judgment? Who carries the consequence when it goes wrong? An operating model is really a decision system in disguise.
  reactions: 1
  insight: "Strong reframe - operating model as decision system"
  replies: []

- id: 1736845700000
  author: "Max Yelisyeyev"
  profile: null
  sentiment: "question"
  content: |
Ownership is where things usually break. When everyone is involved, no one is accountable for value or risk. What have you seen work better: central AI ownership or pushing accountability into business units?
  reactions: 1
  insight: "Good question about ownership model"
  replies: []
```

## Our Engagement

```yaml
- id: 1736846000000
  type: "comment"
  status: "posted"
  sentiment: "positive"
  content: |
This is exactly what we've been saying: workflow first, tools last. The tool is 20% of the outcome. The workflow is 80%.

Most teams start with "which AI tool should we buy?". Wrong question. Start with: which workflow, definition of done, ownership, validation, etc.

Only then pick the tool. The tool is 20% of the outcome. The workflow is 80%.

Speed without those answers just produces faster wrong answers.
  strategy: "Add Context - Share our 'workflow first, tools last' framework with specific questions to ask"
  grounded_in:
    - content/innomize/ai-adoption-workflow-first.md
  replies: []
```

## Notes

- Very strong alignment with our "workflow first, tools last" framework
- His governance/process/ownership/adoption maps directly to our framework
- His "speed without direction" echoes our "faster wrong answers" insight
- Good engagement from comments - thoughtful audience
- First engagement with this person
