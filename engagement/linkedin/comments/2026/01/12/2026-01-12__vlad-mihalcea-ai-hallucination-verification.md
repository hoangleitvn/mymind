---
type: linkedin-engagement
created: '2026-01-12T08:10:00Z'
last_updated: '2026-01-12T08:10:00Z'

author:
  name: "Vlad Mihalcea"
  linkedin_url: "https://ro.linkedin.com/in/vladmihalcea"
  profile: "people/vlad-mihalcea.md"

post:
  source: "external"
  url: "https://www.linkedin.com/posts/vladmihalcea_as-a-software-engineer-you-need-to-acquire-activity-7416385614121594880-xAyj"
  activity_id: "7416385614121594880"
  date: '2026-01-12'
  reactions: 50
  comments_count: 0
  reposts: 0
  theme: "AI literacy and professional engineering skills"
  angle: "Knowledge as defense against AI hallucinations"
  key_points:
    - Engineers need enough knowledge to think for themselves
    - Detecting AI hallucinations separates professionals from amateurs
    - Continuous learning is the only way to build this capability
  hashtags: []

thread_topic: "AI verification skills for engineers"
topic_tags: [ai-development, engineering-skills, ai-hallucination, continuous-learning]

engagement_status: "conversation"
response_received: true
follow_up_needed: false
follow_up_date: null
---

## Original Post

As a software engineer, you need to acquire enough knowledge to be able to think for yourself. This has always been the case, as, otherwise, you'd fall for Cargo Cult programming or follow irrelevant trends. Today, this is even more relevant. Being able to tell whether AI is correct or hallucinates is what differentiates professional engineers from amateur coders. And, the only way to increase your knowledge is to never stop learning. Reading good books, watching relevant courses, participating in workshops, and building prototypes will give you an edge over other humans or machines.

## Notable Comments

```yaml
[]
```

## Our Engagement

```yaml
- id: 1736669400000
  type: "comment"
  status: "posted"
  sentiment: "positive"
  content: |
The pattern I keep seeing: teams adopt AI tools but skip building the verification muscle. They trust the output because it sounds confident.

The engineers who catch hallucinations? They've already debugged that problem manually. Domain knowledge becomes the filter.
  strategy: "Add Context - Extend his verification point with observed pattern from teams"
  replies:
    - id: 1736672400000
      author: "Vlad Mihalcea"
      sentiment: "positive"
      content: |
It's understandable. Humans are wired to follow the Path of Least Resistance. It's an evolutionary trait that allows us to conserve energy.

However, this is very detrimental in this case. Those who will build the proper habits to validate will win over those who don't.
      reactions: 0
    - id: 1736672500000
      type: "our_reply"
      status: "posted"
      sentiment: "positive"
      content: |
Yeah, each person has different ways, lots of shortcuts. I did that too. But I think the habits should be: treat AI output like a junior developer's PR. Review it, don't just merge it. Teams that build this muscle early avoid the expensive debugging sessions later.
    - id: 1736673600000
      author: "Unknown"
      sentiment: "question"
      content: |
Hoang Le What's the connection between domain knowledge and good verification/review/testing habits?
      reactions: 0
    - id: 1736673700000
      type: "our_reply"
      status: "posted"
      sentiment: "positive"
      content: |
Domain knowledge is your expertise combined with thinking and judgment. AI amplifies that - brainstorming, exploring options.

The trap: AI generates plausible-looking outputs. The more you generate at once, the higher the cognitive load. At some point you stop verifying and just accept.

Your expertise is the filter that catches what "looks right" but isn't.
    - id: 1736678400000
      author: "Alex Johnson"
      sentiment: "positive"
      content: |
For sure. That only comes with hard-earned experience, "time in the game" that can't be replaced with tools or theory.

Another thing that helps is domain knowledge in the sense of "subject matter expert". E.g., being a good driver helps you write autonomous vehicle code, etc.
      reactions: 0
    - id: 1736678500000
      type: "our_reply"
      status: "posted"
      sentiment: "positive"
      content: |
Exactly. The autonomous vehicle example is perfect. You can't verify what you've never experienced failing.

Same reason the best AI code reviewers are engineers who've debugged those exact problems manually before.
```

## Notes

- Vlad is a well-known figure in Java/Hibernate ecosystem with 84K followers
- Post aligns with our AI adoption themes
- His point about Cargo Cult programming is relevant to vibe coding concerns
- Potential target for relationship building given overlapping themes
- Good thread engagement: Vlad replied, another person asked follow-up question
- "Junior developer's PR" analogy landed well - reusable framing
