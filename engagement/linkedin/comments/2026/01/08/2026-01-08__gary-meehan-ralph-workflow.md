---
type: linkedin-engagement
created: '2026-01-08T02:10:00Z'
last_updated: '2026-01-08T02:10:00Z'

author:
  name: "Gary Meehan"
  profile: "people/gary-meehan.md"

post:
  source: "external"
  url: "https://www.linkedin.com/posts/gary-meehan_ralph-aicoding-softwareengineering-activity-7414584133777313792-0zsE"
  activity_id: "7414584133777313792"
  date: '2026-01-07'
  reactions: 12
  comments_count: 0
  reposts: 0
  theme: "AI coding workflows - Ralph technique"
  angle: "Better harnesses over smarter agents"
  key_points:
    - Ralph is a workflow technique, not a product (by Geoffrey Huntley)
    - Fresh context per task - clears window after each ticket
    - Memory via filesystem (prd.json, progress.txt, git)
    - Feedback loop - implement, test, retry/commit, next
    - Treats development like factory line
  hashtags: ["Ralph", "AIcoding", "SoftwareEngineering", "FutureOfWork", "DevTools"]

thread_topic: "Ralph AI coding workflow technique"
topic_tags: [ai-development, agent-workflows, vibe-coding, automation]

engagement_status: "posted"
response_received: false
follow_up_needed: false
follow_up_date: null
---

## Original Post

Everyone is talking about "Ralph." It ships features while you sleep. üò¥üö¢ The AI engineering space is currently obsessing over a new concept called Ralph. What makes Ralph interesting is that it isn't a product you buy. It's a workflow you build. Created by Geoffrey Huntley, "Ralph" is a technique, not a tool. It strips away the complex orchestration of agent swarms and replaces it with a simple, brute force loop that runs while you sleep. Here is why this approach is catching fire: üß† Fresh Context Every Time Most agents get "tired" or confused as the chat history gets too long. Ralph clears the context window after every single task. It approaches every ticket with a fresh brain, checking the code, running the tests, and moving on. üìù Memory via Files, Not Context Instead of trying to remember everything in the LLM's context window, Ralph relies on the file system. - prd.json: The to do list. - progress.txt: The long term memory/learnings. - git: The history. üîÑ The Feedback Loop This is the "secret sauce." It doesn't just write code; it runs a feedback loop. 1. Pick a user story. 2. Implement it. 3. Run npm run typecheck and tests. (or similar) 4. If it fails, retry. If it passes, commit and move to the next. It essentially treats software development like a factory line rather than a creative writing session. The Verdict? I haven't run it myself yet, I'm planning to set up a ralph.sh loop later this week to see what it can do! So we don't need smarter agents! We need better harnesses for the agents we already have. Have you tried it out yet?

## Notable Comments

```yaml
- id: 1736305200000
  author: "Michael Eric Walter Wegener"
  profile: null
  sentiment: "positive"
  content: |
I have Junie, Cline and Jane - they will try Ralph now.
  reactions: 1
  insight: "Early adopter testing multiple AI tools"
  replies: []
```

## Our Engagement

```yaml
- id: 1736305800000
  type: "comment"
  status: "posted"
  sentiment: "positive"
  content: |
The harness insight is sharp. Fresh context per task solves the "tired agent" problem.

But the feedback loop only catches what tests catch. If tests don't exist for a user story, Ralph commits and moves on. That's where the debt sneaks in.

I've been experimenting with similar patterns. Prefer local memory over external protocols like MCP. Filesystem as source of truth, git as history. Simpler debugging, no network dependencies.

This connects to the Recursive Language Model research from MIT. RLM uses Python REPL to navigate context. Ralph uses filesystem for memory. Different mechanics, same principle: offload context management to infrastructure, not the model.

The trend is clear. Agent harnesses and workflows are the layer that matters now.
  strategy: "add-experience - shares personal experimentation, connects to RLM engagement, positions on local-first approach"
  replies: []
```

## Notes

- Gary is exploring AI coding workflows, similar focus to my content
- Post aligns with my "Vibe Coding Awareness" thesis about understanding what you ship
- Connects to previous RLM engagement with Shubham Saboo (2026-01-07)
- Both RLM and Ralph are external orchestration patterns - emerging trend
- Personal stance: local memory (filesystem) over external protocols (MCP)
- Geoffrey Huntley created Ralph - could be worth following
- Good opportunity to establish credibility on AI-assisted development topic
