---
type: linkedin-engagement
created: '2026-01-05T00:00:00Z'
last_updated: '2026-01-05T00:00:00Z'

author:
  name: "Andrea Laforgia"
  profile: "https://www.linkedin.com/in/andrealaforgia/"

post:
  source: "external"
  url: "https://www.linkedin.com/posts/andrealaforgia_ai-artificialintelligence-softwaredevelopment-activity-7413640014028288000-ol9c"
  date: '2025-01-04'
  reactions: null
  comments_count: null
  reposts: null
  theme: "AI-generated code trustworthiness"
  angle: "Non-determinism does not equal unreliability"
  key_points:
    - Non-deterministic inputs don't prevent deterministic systems
    - What matters is behavior, not how we got there
    - Humans are equally non-deterministic yet ship reliable software
    - Testing and review validate external behavior regardless of generation method
    - Refactoring proves implementation paths matter less than outcomes
  hashtags: [AI, ArtificialIntelligence, SoftwareDevelopment]

thread_topic: "AI code trustworthiness and specification-driven development"
topic_tags: [ai-coding, non-determinism, spec-driven, behavior-vs-output, vibe-coding]

engagement_status: "posted"
response_received: false
follow_up_needed: true
follow_up_date: null
---

## Original Post

Andrea Laforgia (17,657 followers) challenges the claim that AI-generated code is untrustworthy because LLMs are non-deterministic.

Core argument: This is a "category error" - conflating process variability with outcome reliability.

Key quote: "What actually matters is behaviour, not how we got there."

Parallels to humans: different engineers solve problems differently, yet reliable software has shipped for decades.

## Our Engagement

```yaml
- id: 1736035500000
  type: "comment"
  status: "posted"
  timestamp: '2026-01-05T00:00:00Z'
  content: |
Agreed. Same with humans - different engineers provide different solutions for the same problem. Even verification processes vary between teams. No one-size-fits-all.

In coding, implementation can change. Refactor, rewrite, swap frameworks. But what doesn't change is the specification - the WHAT and WHY.

One pattern I keep seeing: teams jump straight to building, vibe coding without workflow or context management. Months later, they've lost all the reasoning behind decisions. Some restart from zero.

Spec-driven development is the right shift. The challenge is applying it consistently - maintaining the right context over time, not just at the start.

Testing validates after. Specification prevents before. But specification also needs to persist.
  strategy: "Validate human parallel, pivot to specification as foundation, add real-world observation about vibe coding consequences, position spec persistence as the next challenge"
```

## Notes

- High-follower author (17k+) - good visibility opportunity
- Strong alignment with our framework: behavior over process, specification over validation
- Added personal observation about vibe coding pattern - differentiates from generic agreement
- New insight surfaced: specification persistence, not just creation
- Worth following up if author responds - potential relationship building
- "Specification needs to persist" could be future content seed
