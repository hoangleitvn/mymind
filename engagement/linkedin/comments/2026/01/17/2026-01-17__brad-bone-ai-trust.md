---
type: linkedin-engagement
created: '2026-01-17'
last_updated: '2026-01-17'

author:
  name: "Brad Bone"
  linkedin_url: "https://www.linkedin.com/in/brad-bone-53551a1a"
  profile: "people/brad-bone.md"

post:
  source: "external"
  url: "https://www.linkedin.com/posts/brad-bone-53551a1a_unpopular-opinion-from-an-ai-guy-regardless-activity-7417741889489100801-8l7Y"
  activity_id: "7417741889489100801"
  date: '2026-01-16'
  reactions: 5
  comments_count: 4
  reposts: 0
  theme: "AI cannot build authentic trust"
  angle: "Machines lack intent, empathy, and accountability"
  key_points:
    - "AI will never build authentic trust or rapport"
    - "Machines are incapable of intent, empathy and accountability"
    - "AI can only simulate these qualities effectively"
  hashtags: []

thread_topic: "AI trust and human qualities"
topic_tags: [ai-trust, ai-philosophy, accountability, systems-thinking]

engagement_status: "posted"
response_received: false
follow_up_needed: true
follow_up_date: '2026-01-19'
---

## Original Post

Unpopular opinion from an AI guy: AI will never build authentic trust or rapport because machines are incapable of intent, empathy and accountability. AI can only simulate these qualities effectively.

## Notable Comments

```yaml
- id: 1736908945000
  author: "Dr. Masayuki Otani"
  profile: null
  sentiment: "constructive-pushback"
  content: |
    Trust in systems depends on predictability, bounded behaviour, auditability,
    and enforceable accountabilityâ€”not empathy. Accountability belongs with system
    owners and operators through governance structures, not with AI models themselves.
  reactions: null
  insight: "Reframes trust as systems property, not emotional quality"
  replies: []

- id: 1736908945100
  author: "Carson Platts"
  profile: null
  sentiment: "constructive-pushback"
  content: |
    Teams misunderstand trust dynamics. Rather than AI creating trust, it should
    focus on preventing trust violations through reliability, coverage, and clear ownership.
  reactions: null
  insight: "Trust as absence of violations, not presence of empathy"
  replies: []
```

## Our Engagement

```yaml
- id: 1737142800000
  type: "comment"
  status: "posted"
  sentiment: "constructive-pushback"
  content: |
You're right that AI lacks intent and empathy. But, trust isn't about feeling understood. It's about predictability.

When I check a weather app, I don't need it to care about my picnic. I need it to be accurate 90% of the time. Same with AI. The question isn't "does it feel?" It's "does it do what it says consistently?"

And I agreed with Dr Masayuki Otani: accountability belongs to system owners, not the model.
  strategy: "Reframe with systems thinking - acknowledge valid point while offering alternative perspective"
  replies: []
```

## Notes

- Brad is an AI professional, posting thought-provoking takes
- Thread already has quality pushback from Dr. Otani and Carson Platts
- My comment builds on existing thread while adding concrete example (weather app)
- Topic aligns with foundation-first thinking (systems reliability over emotional appeal)
