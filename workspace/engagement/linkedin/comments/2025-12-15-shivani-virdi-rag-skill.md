---
type: linkedin-engagement
created: '2025-12-15'
last_updated: '2025-12-15'

author:
  name: "Shivani Virdi"
  profile: "people/shivani-virdi.md"

post:
  source: "external"
  url: "https://www.linkedin.com/posts/shivanivirdi_if-i-had-to-bet-on-one-skill-in-ai-as-an-activity-7406181531481886720-1O1y"
  date: '2025-12-15'
  reactions: 27
  comments_count: 10
  reposts: 0
  theme: "ai-engineering"
  angle: "rag-skills"
  key_points:
    - "Bigger context â‰  better context"
    - "Tokens aren't free at scale"
    - "You can't brute-force context, you need to engineer it"
    - "RAG learning roadmap with resources"
  hashtags: []

notable_comments:
  - author: "Sparsh Kandpal"
    content: "Larger context windows come with clear trade-offs, higher token costs and increased risk of context dilution"
    reactions: 1
    insight: "Context dilution angle"
  - author: "Julia Lenc"
    content: "You can't brute-force context. Love it."
    reactions: 1
    insight: "Amplifying key line"

our_engagement:
  - id: 1
    type: "comment"
    reply_to: null
    status: "posted"
    timestamp: '2025-12-15'
    content: |
Agreed. Bigger context doesn't mean better results.

The key question: how do we know what is enough?

My approach: train AI to speed up following your workflow. Figure out what needs to be added, what needs to be removed.

Forcing yourself to think about retrieval = forcing yourself to understand your data.

If you don't understand your data, AI won't. And hallucination will come.
    strategy: "Supportive agreement + personal approach - adds practical workflow angle, connects understanding data to hallucination"

engagement_status: "posted"
---

## Post Analysis

Shivani (74K followers) makes case for RAG as essential AI skill. Strong technical content with learning roadmap. Key insight: "You can't brute-force context."

## Comment Strategy

Agree with core premise, add the "how do we know what's enough" question, share personal workflow approach, close with hallucination consequence.
