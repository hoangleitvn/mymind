---
type: linkedin-engagement
created: '2025-12-15T00:00:00Z'
last_updated: '2025-12-15T00:00:00Z'

author:
  name: "Shivani Virdi"
  profile: "people/shivani-virdi.md"

post:
  source: "external"
  url: "https://www.linkedin.com/posts/shivanivirdi_if-i-had-to-bet-on-one-skill-in-ai-as-an-activity-7406181531481886720-1O1y"
  date: '2025-12-15'
  reactions: 27
  comments_count: 10
  reposts: 0
  theme: "ai-engineering"
  angle: "rag-skills"
  key_points:
    - "Bigger context does not equal better context"
    - "Tokens aren't free at scale"
    - "You can't brute-force context, you need to engineer it"
    - "RAG learning roadmap with resources"
  hashtags: []

thread_topic: "RAG as essential AI engineering skill"
topic_tags: [ai-engineering, rag, context-engineering, llm]

engagement_status: "posted"
response_received: false
follow_up_needed: false
follow_up_date: null
---

## Original Post

If I had to bet on one skill in AI as an engineer. Bigger context does not equal better context. Tokens aren't free at scale. You can't brute-force context, you need to engineer it. RAG learning roadmap with resources.

## Notable Comments

```yaml
- id: 1734220800001
  author: "Sparsh Kandpal"
  profile: null
  sentiment: "positive"
  content: |
    Larger context windows come with clear trade-offs, higher token costs and increased risk of context dilution
  reactions: 1
  insight: "Context dilution angle"
  replies: []

- id: 1734220800002
  author: "Julia Lenc"
  profile: null
  sentiment: "positive"
  content: |
    You can't brute-force context. Love it.
  reactions: 1
  insight: "Amplifying key line"
  replies: []
```

## Our Engagement

```yaml
- id: 1734220800100
  type: "comment"
  reply_to: null
  status: "posted"
  timestamp: '2025-12-15T00:00:00Z'
  content: |
    Agreed. Bigger context doesn't mean better results.

    The key question: how do we know what is enough?

    My approach: train AI to speed up following your workflow. Figure out what needs to be added, what needs to be removed.

    Forcing yourself to think about retrieval = forcing yourself to understand your data.

    If you don't understand your data, AI won't. And hallucination will come.
  strategy: "Supportive agreement + personal approach - adds practical workflow angle, connects understanding data to hallucination"
```

## Notes

- Shivani (74K followers) makes case for RAG as essential AI skill
- Strong technical content with learning roadmap
- Key insight: "You can't brute-force context."
- Added the "how do we know what's enough" question and hallucination consequence
