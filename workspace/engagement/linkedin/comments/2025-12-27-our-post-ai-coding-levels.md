---
type: linkedin-engagement
created: '2025-12-25T02:22:42Z'
last_updated: '2025-12-27T07:25:00Z'

author:
  name: "Hoang Le"
  profile: null

post:
  source: "our-post"
  url: "https://www.linkedin.com/feed/update/urn:li:activity:7409780431983816704/"
  date: '2025-12-25'
  reactions: 7
  comments_count: 5
  reposts: 0
  theme: "6 levels of AI coding progression"
  angle: "Framework for understanding AI coding maturity"
  key_points:
    - Level progression from L0 (no AI) to L5 (AI reasons about system)
    - L2 to L3 is the critical transition for most teams
    - Understanding model BEHAVIOR vs fixing OUTPUT
    - System identity enables L5 reasoning
  hashtags: []

thread_topic: "6 levels of AI coding progression"
topic_tags: [ai-coding, reasoning-models, engineering-mindset, level-progression]

engagement_status: "active"
response_received: true
follow_up_needed: false
follow_up_date: null
---

## Original Post

See source file: published/linkedin/levels-of-ai-coding.md

## Notable Comments

```yaml
- id: 1735282800000
  author: "palin H."
  profile: null
  sentiment: "positive"
  content: |
    That's very nice explanation
  reactions: 1
  insight: "Generic praise, early commenter"
  replies: []

- id: 1735283400000
  author: "Unknown"
  profile: null
  sentiment: "positive"
  content: |
    Hoang Le Thanks for sharing this, Hoang! I'm currently stuck at Level 2 — 'AI writes code I review' — and trying to move toward Level 3. The idea of specifying *how* with scaffolding and guardrails really speaks to me.
  reactions: 0
  insight: "Genuine experience sharing, seeking guidance on Level 2 to 3 transition"
  replies: []
```

## Our Engagement

```yaml
- id: 1735283700000
  type: "reply"
  reply_to: 1735282800000
  status: "draft"
  timestamp: '2025-12-27T00:00:00Z'
  content: |
    Appreciate that, Palin! Tried to make the framework practical rather than abstract.
  strategy: "Brief acknowledgment for generic praise, reinforces post value"

- id: 1735284000000
  type: "reply"
  reply_to: 1735283400000
  status: "posted"
  timestamp: '2025-12-27T00:00:00Z'
  content: |
    Level 2 to 3 is where most teams are right now. You're in good company.

    Here's a shift that helped: pay attention to what you keep fixing. Same naming issues? Same error handling gaps? Those patterns reveal what the model defaults to.

    Once you see the behavior, you can add targeted instructions to override it. That's Level 3. You're not fixing output anymore, you're shaping behavior upfront.

    Level 4 is when you trust the model enough to remove those instructions one by one.
  strategy: "Validate position, bridge output-fixing to behavior-shaping, show progression path"

- id: 1735284600000
  type: "reply"
  reply_to: 1735284300000
  status: "posted"
  timestamp: '2025-12-27T07:25:00Z'
  content: |
    That's the goal. The 4 to 5 shift is less about prompting and more about capturing your system's identity. When the model knows WHO your codebase is, it reasons differently.

    Keep experimenting. Share what you find.
  strategy: "Point to L5 system identity, encourage continued learning"
```

## Notes

- Post performing well with 7 reactions and 5 comments in 2 days
- Strong first comment thread with Vercel case study details
- Level 2 commenter represents target audience for this content
- Palin H. early engagement helped traction
- Key insight from discussion: the bridge from Level 2 to 3 is understanding model BEHAVIOR, not just fixing OUTPUT
